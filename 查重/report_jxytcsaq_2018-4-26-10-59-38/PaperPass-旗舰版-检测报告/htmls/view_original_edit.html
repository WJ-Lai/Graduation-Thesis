<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>修改文档</title>
    <link href="css/bootstrap.css" rel="stylesheet" />
    <link href="css/style.css" rel="stylesheet" />
</head>
<body>
<div class="bg-grey PLR40">

    <div class="paper-txt P30 PB0">
        <div class="alert alert-success" role="alert">此为您在“详细报告”中修改后临时保存的内容，编辑过的内容会变绿色</div>
        <p class="text-idt25" data-id="1">绪 论</p><p class="text-idt25" data-id="2">研究背景与意义</p><p class="text-idt25" data-id="3">十字路口汇聚了城市道路各个方向的交通， 作为交通系统的重要组成部分，在城市交通系统中占据重要的地位。交叉路口存在多处冲突点（如图1-1），机动车与行人之间，机动车和机动车或非机动车之间相互干扰严重，因此，十字路口以及其附近区域属于交通事故的多发地点。预防和管控十字路口事故，提高城市道路的安全性和通畅性，已成为道路交通研究不可缺失的主题。若能提前预测驾驶意图，可有利于减少十字路口事故发生率。</p><p class="text-idt25" data-id="4">交叉口高峰小时冲突类型及分布</p><p class="text-idt25" data-id="5">作为获取信息的主要通道，驾驶员的视觉系统有着非常重要的作用，而驾驶人的视觉特性与驾驶意图之间存在密切联系。因此，可以通过十字路口驾驶员动态视觉搜索模式来预测驾驶员的驾驶意图，进而可以降低十字路口的伤亡率。</p><p class="text-idt25" data-id="6">国内外研究现状</p><p class="text-idt25" data-id="7">国内研究现状</p><p class="text-idt25" data-id="8">我国经济发展较西方国家起步较晚，汽车产业更是滞后于西方发达国家，因而对汽车技术的相关研究也比国外落后，在驾驶员视觉特性方面的应用比国外少。但近些年来，有研究人员在这方面也做出了不少贡献，对驾驶员的驾驶行为及意图方面的研究也在不断进行中。</p><p class="text-idt25" data-id="9">长安大学的马勇[1]等人研究了汽车速度与道路标志字体高度的关系及其对驾驶员视觉搜索广度、注视视角分布和注视持续时间的影响。并发现驾驶员对道路中心区域的注视频率最高，并且总是较多地关注道路左侧区域及距车辆较近的区域，车速的提高使得驾驶员对远处区域的注视逐渐增多。</p><p class="text-idt25" data-id="10">吉林大学的冀秉魁[2]对驾驶员在城市道路交通环境下行驶过程中的驾驶行为进行了预测。他通过分别对驾驶员在跟驰、超车以及换道（包括左换道和右换道）行为及视觉特征的表征参数的变化规律进行了深入分析和研究，并且选取了具有典型特征的表征参数作为模型参数，以隐马尔科夫理论为基础建立模型，找出了驾驶意图和驾驶行为的关系，成功对驾驶意图做出预测。</p><p class="text-idt25" data-id="11">施晓芬[3]在现实道条件下进行行了实车实验。通过将一个完整的交叉口行驶过程划分成18种情况，并根据不同的情况，分析驾驶员进入和经过十字路口时的对车速的控制方式以及视觉搜索模式。发现驾驶员即时采用不同的通行方式进入和通过十字路口，对前方道路区域的关注度始终最高，并且搜索方式主要为从前方道路区域转换到某一区域后再回到前方道路区域。</p><p class="text-idt25" data-id="12">东南大学的王芳等人[4]通过室内驾驶员眼动试验，详细分析了驾驶员在不同公路平面线形条件下的驾驶员搜索模式特性。发现驾驶员在直线段的注视持续时间明显高于曲线段，且视野范围明显小于曲线段的视野范围，注视点出现前移现象，从而说明了曲线段的视觉信息高于直线段。</p><p class="text-idt25" data-id="13">合肥工业大学的朱人可[5]将驾驶员注视总时长、视角特性、注视持续时长和视角搜索广度几个参数作为视觉搜索模式的基本特性参数，使用眼动仪记录了驾驶人在昼夜不同环境下驾驶过程中的眼动数据，发现驾驶人的水平视角、垂直视角、视觉热点以及注视频次等参数随着昼夜环境变化存在盘著性差异，具体表现为白天时，视觉搜索范围更广，而夜间则更倾向于关注前方中远距离。</p><p class="text-idt25" data-id="14">彭金栓[6]根通过采集驾驶员的视觉搜索、操作特性、车辆运动状态等参数对驾驶员的车辆变道的决策机制进行深入分析，并分别采用证据理论与 Logistic模型对换道行为建模预测。结果表明，驾驶员对后视镜的关注度可以体现其的换道意图，且在意图换道时，会对当前车道的注意力降低。</p><p class="text-idt25" data-id="15">吉林大学的杨诚[7]基于隐马尔可夫理论，选取了能够表征驾驶人视觉特性的6个参数，即对后视镜的注视次数、注视时间、注视点转移路径、扫视幅度、扫视速度和头部转角，利用 MATLAB软件自带的 HMM工具箱编程，建立了驾驶人换道意图识别模型，并利用测试样本对识别模型进行验证。其研究建立了有较高的识别准确率的模型，因此为驾驶意图研究方面提供了重要的参考。</p><p class="text-idt25" data-id="16">国外研究现状</p><p class="text-idt25" data-id="17">国外在驾驶意图和驾驶行为预测的方向上进展比国内早，研究也具有特点，值得国内研究人员所学习。</p><p class="text-idt25" data-id="18"> Olsen E等人[8]把驾驶员实际驾驶过程中的注视点划分为多个注视区域，研究换道过程中注视点与驾驶意图的规律，发现向左换道前驾驶人对左侧兴趣区域的关注程度约为直行时的2倍。</p><p class="text-idt25" data-id="19"> Salvucci D D等人[9]通过驾驶模拟器，研究在高速公路环境中车道改变的时间与眼动行为关系时，发现司机将他们的主要视觉焦点在车道变更发生后，立即从起跑线转向到达目的地车道。</p><p class="text-idt25" data-id="20"> Mori M等人[10]通过驾驶员行驶过程中脸部的视频，采用手动标记驾驶员的注视方向的方式，研究驾驶员意识与注视行为、碰撞风险之间的关系。他们计算了注视资源在汽车八个区域内的资源分布，并发现注视行为存在个体差异，专家司机的意识水平比非专家司机高。</p><p class="text-idt25" data-id="21">Liu A[11]提出驾驶员当前的控制动作、视觉搜索行为以及机动车周围的交通情形可用于推测驾驶员意图。在实际实验中，仅通过驾驶员的控制动作（即转向和加速动作），成功推断出了驾驶员的驾驶意图，并讨论了使用注视信息进一步改进的可能性。</p><p class="text-idt25" data-id="22"> Werneke J和 Vollrath M[12]采用驾驶模拟器研究了交叉路口复杂度对驾驶员驾驶意图和驾驶行为的影响，同时用实验来探究驾驶员注视特性、车辆反应等对驾驶员在交叉路口处驾驶意图的影响。其研究表明驾驶员的注视特性——注意力分配这一项对驾驶员在交叉路口处的驾驶意图产生明显影响，且最不复杂的交叉路口显示出最多的意外。</p><p class="text-idt25" data-id="23">Faure V等人[13]通过改变驾驶环境的复杂性与引入次级任务，采用模拟驾驶的方式，研究眨眼与驾驶员心理负荷的关系。实验表明，眨眼频率可有效反映驾驶员心理状态，当任务难度增加时，眨眼频率下降，同时发现当引入次级任务时，眨眼持续时间没有受到影响。</p><p class="text-idt25" data-id="24"> Peng J等人[14]通过离线数据分析提取车道变换和车道保持期间的驾驶行为特征，根据驾驶员视觉搜索特征、车辆操作行为、车辆运动状态和驾驶条件构建综合预测指标体系。然后建立一个神经网络模型来预测车道变化行为。</p><p class="text-idt25" data-id="25">Winsum W V等人[15]采用了驾驶模拟器的方法，研究变换车道过程中车速、车道宽度以及行驶方向的驾驶员感知信息与车辆响应之间的关系。他们将车道变换分成三个连续的状态，认为驾驶员的操作行为是受其前一阶段驾驶行为的结果所控制的，并研究视觉和车道变换策略选择的关系。</p><p class="text-idt25" data-id="26">主要研究内容</p><p class="text-idt25" data-id="27">本研究基于 MATLAB在现有数据库基础上，采用特征筛选算法遴选最优表征参数，通过聚类方法析取驾驶员的动态视觉搜索模式，并且将聚类结果与有监督学习相结合，提出一种提高分类准确率的新方法。本论文的主要内容及组织结构如下：</p><p class="text-idt25" data-id="28">第1章 绪论。介绍本次研究的背景以及意义，对近年来国内外在相关领域的研究成果进行了总结分析，最后说明本文的主要研究内容以及结构安排。</p><p class="text-idt25" data-id="29">第2章 研究方法。本章主要阐述论文的研究思路以及方法，同时也对课题内重要的参数的介绍。</p><p class="text-idt25" data-id="30">第3章 数据预处理。首先在数据库内提取实验所需数据并整合，然后进行特征选择，得到对分类器起主要作用的特征。</p><p class="text-idt25" data-id="31">第4章 模式析取。本章首先以相关系数、簇内样本数为参考，优选出最佳聚类参数。接下来采用层次聚类算法，得到不同驾驶意图下的动态视觉搜索模式，并进行对聚类后结果进行分析。</p><p class="text-idt25" data-id="32">第5章 建模和预测。本章首先对本课题所采用的有监督学习算法进行介绍，继而提出一种将聚类结果与有监督学习结合的新预测方法，并与传统有监督学习方法进行比较。</p><p class="text-idt25" data-id="33">第6章 结论。归纳总结了实验结果，并梳理研究中主要结论。</p><p class="text-idt25" data-id="34"> </p><p class="text-idt25" data-id="35">研究方法</p><p class="text-idt25" data-id="36">本章主要对研究方法及过程进行总述，其中包括数据库的构建以及对本课题中重要的三个参数——信号灯、驾驶意图和视觉特征进行介绍。</p><p class="text-idt25" data-id="37">研究方法总述</p><p class="text-idt25" data-id="38">本论文的研究流程如图2-1所示。</p><p class="text-idt25" data-id="39">论文研究方法流程图</p><p class="text-idt25" data-id="40">研究过程中，首先对现有数据进行分析整理，这里面包括提取必要数据和对相应数据的整合。其中，十字路口处驾驶员的驾驶意图分为三种：左转、右转、直行，那么根据这三种驾驶意图，驾驶员在同一种十字路口处也会表现出不同的注视特性。那么作为对比，也选取两种十字路口做一个分析。</p><p class="text-idt25" data-id="41">第二步，进行数据预处理。对提取后的数据，进行特征选择和归一化。特征选择可减少数据的维度、去除无关数据特征，可有效提高分类器性能。在本研究中，采用FEAST（a FEAture Selection Toolbox for C and MATLAB）算法与显著性检验结合进行特征的选择。</p><p class="text-idt25" data-id="42">第三步，析取驾驶员动态视觉搜索模式。采用层次聚类算法，得到不同信号灯情况下，驾驶员在表现出不同驾驶意图时的视觉搜索模式，并进行结果分析</p><p class="text-idt25" data-id="43">第四步，提出一种将聚类结果与有监督学习结合的新预测方法。其中，有监督学习采用支持向量机（Support Vector Machine）和随机森林（Random Forest）两种方法。最后，对新方法与传统方法进行效能比对，分析数据得出结论。</p><p class="text-idt25" data-id="44">数据库构建</p><p class="text-idt25" data-id="45">本毕业设计研究的数据采集方法主要为视频采集，并且以调查问卷为辅佐。</p><p class="text-idt25" data-id="46">视频采集数据具体方法为：将配有前后摄像头的行车记录仪安装在实验车，拍摄记录10位实验人员在约一周内的驾驶行为，并且在后期进行人工的视频分析从而提取出实验人员的驾驶注视行为、驾驶时间、驾驶状态、信号灯种类等信息，建立起基本的驾驶员视觉信息数据库。</p><p class="text-idt25" data-id="47">数据采集调查问卷收集为辅佐，问卷内容针对驾驶员的驾驶行为及驾驶风险性量化进行提问。</p><p class="text-idt25" data-id="48">本毕业设计采用上述数据库进行后续的研究。</p><p class="text-idt25" data-id="49">基本参数描述</p><p class="text-idt25" data-id="50">信号灯</p><p class="text-idt25" data-id="51">信号灯是一种用于交通管理的重要工具，可有效减少交通事故率，提高城市道路使用率。信号灯分为机动车信号灯和非机动车信号灯，本文所研究的对象为驾驶员，因此后文中信号灯均指代的机动车信号灯。常见的机动车信号灯由红色、黄色、绿色三中无图案圆形单位组成，驾驶员需根据路口信号灯的颜色做出相应的驾驶行为。红灯状态下，机动车严禁通行。绿灯状态下，允许机动车通行。黄灯状态下，若机动车已经超过停止线，可以继续向前通行。</p><p class="text-idt25" data-id="52">十字路口处的红绿信号灯的颜色很大程度上影响了驾驶员的行为。黄灯情况下，驾驶员会根据机动车的位置而做出不同的行为。绿灯和红灯情况下，驾驶员的行为较黄灯而言更为统一且信号灯状态保持时间较长，因此，在本研究中选取绿灯和红灯两种典型的信号灯状态进行研究。</p><p class="text-idt25" data-id="53">驾驶意图</p><p class="text-idt25" data-id="54">驾驶员在十字路口处的驾驶意图主要有左转、右转和直行三种，因此本次研究属于一个三分类问题。我们所要研究的驾驶意图预测是基于上述三种驾驶意图。</p><p class="text-idt25" data-id="55">驾驶意图是驾驶员的一种内在心理响应，因此必然存在相应的外在响应将其反映。常见的外在响应可以为肢体上的行为，比如说手动方向盘的控制、脚对油门刹车的控制，也可以为驾驶员的视觉特征，比如说眼睛关注前方车道。人的潜意识会以各种形式展示，但眼睛是驾驶员获取道路信息最主要的渠道，因此在本研究中选取视觉特征作为驾驶意图预测的重要参数。</p><p class="text-idt25" data-id="56">视觉特征</p><p class="text-idt25" data-id="57">驾驶员的视觉特征展示的是眼球运动的特性。在驾驶过程中，驾驶员的视觉特征可以用于表示驾驶员注意力变化的规律。在经过十字路口时，驾驶员会根据后续的驾驶行为做出相应的注意力转移，包括注视区域的变化、注视时间的变化等等。</p><p class="text-idt25" data-id="58">为了更好的描述驾驶员视觉变化的规律，本次研究将在十字路口处的车内车外大致分为13个区域，从而将视觉特性量化。图2-2是13个区域的划分。这些区域包括：1前方道路、2右前方道路、3后视镜、4左视镜、5右视镜、6信号灯、7仪表盘、8左侧、9右侧、10中控区、11乘客、12左侧道路区域、13其他。</p><p class="text-idt25" data-id="59">十字路口行车区域划分</p><p class="text-idt25" data-id="60">描述视觉变化规律的特征较多，在这里同样是选取具有典型意义的特征作为研究驾驶员驾驶意图的视觉特性。一是驾驶员注视某一区域的总时长，其定义为注视时长（Duration）。二是驾驶员注视某一区域的总次数，其定义为注视频次（Frequency）。三是驾驶员注视区域的转移，即从某一区域转移到另一区域的概率，其定义为转移概率（Transition Probability）。</p><p class="text-idt25" data-id="61">下面对转移概率计算方法进行介绍，转移概率具体计算方式如公式（1-1）：</p><p class="text-idt25" data-id="62">区域X到区域Y的转移次数/区域X到所有区域的总转移次数（1-1）</p><p class="text-idt25" data-id="63">各视线区域之间的相互转移如图2-3所示，驾驶员视线可以从某一区域转移到其它区域，驾驶员视线由 Ax转移到 Ay称为一种驾驶员视线转移形态，例如，驾驶员视线由区域1（前方道路）转移到区域2（右前方道路）就构成了一次视线转移。驾驶员的视线转移可以表征出驾驶员此刻关注的对象，能为预测驾驶员下一步驾驶行为提供一定程度的帮助，从而达到借助视线转移预测驾驶员驾驶意图的目的。</p><p class="text-idt25" data-id="64">视线关注区域转移示意图</p><p class="text-idt25" data-id="65">计算一定时间范围内，驾驶员的视线转移概率的方法如式(1-2)所示：</p><p class="text-idt25" data-id="66"> a_ xy= p( q_( t+1)= A_ y q_ t= A_ x)= p( q_ t= A_ x， q_( t+1)= A_ y)/ p( q_ t= A_ y)(12)</p><p class="text-idt25" data-id="67">其中， p( q_ t= A_ x， q_( t+1)= A_ y)为联合估计概率， p( q_ t= A_ y)为边缘概率。</p><p class="text-idt25" data-id="68">根据大数定理，当统计量较大时，概率可用相对频数做估计，即：</p><p class="text-idt25" data-id="69"> p( q_ t= A_ x， q_( t+1)= A_ y)≈ w( q_ t= A_ x， q_( t+1)= A_ y)/(∑_( x=1)^ N▒ w( q_ t= A_ y))</p><p class="text-idt25" data-id="70"> p( q_ t= A_ x)≈ w( q_ t= A_ x)/(∑_( x=1)^ N▒ w( q_ t= A_ x))(1-3)</p><p class="text-idt25" data-id="71">将以上两式代入式(1-2)，可得：</p><p class="text-idt25" data-id="72"> a_ xy= p( q_( t+1)= A_ y q_ t= A_ x)= w( q_ t= A_ x， q_( t+1)= A_ y)/ w( q_ t= A_ x)(1-4)</p><p class="text-idt25" data-id="73">其中 q_ t为上一阶段视线所在区域， w为视线从 A_ x转移到 A_ y的次数， a_ xy∈[0，1]，为视线转移概率指标，∑_( y=1)^ N▒ a_ xy=1， N是视线区域的数量，1≤ x， y≤ N.视线转移矩阵可以定义为 D={ a_ xy}。如果a_xy 接近于0，则表明其对应的区域之间的视线转移极少发生。A_x、A_y为第x和第y个视线关注区域。</p><p class="text-idt25" data-id="74"> </p><p class="text-idt25" data-id="75"> </p><p class="text-idt25" data-id="76">数据预处理</p><p class="text-idt25" data-id="77">本章将描述研究中数据预处理的过程。其中包括，提取红绿灯数据、归一化和特征选择的过程。通过筛选的到十个优选特征，为后续的研究做铺垫。</p><p class="text-idt25" data-id="78">关于数据提取和数据处理的相关内容均为MATLAB编程完成，相关程序见附录。</p><p class="text-idt25" data-id="79">提取红绿灯数据</p><p class="text-idt25" data-id="80">由于数据库内存在于本研究中不相关的数据，例如驾驶状态、驾龄、其他路口类型等等，因此需要自行编程提取出本研究中所需数据。</p><p class="text-idt25" data-id="81">本研究中涉及信号灯状态、驾驶员驾驶意图以及视觉特征（注视时长、注视频次和转移概率）。</p><p class="text-idt25" data-id="82">提取后数据总览如表3-1所示。</p><p class="text-idt25" data-id="83">红绿灯数据样本量</p><p class="text-idt25" data-id="84">驾驶意图绿灯红灯</p><p class="text-idt25" data-id="85">左转个数，个2826</p><p class="text-idt25" data-id="86">直行个数，个6154</p><p class="text-idt25" data-id="87">右转个数，个3516</p><p class="text-idt25" data-id="88">总数，个12496</p><p class="text-idt25" data-id="89">在提取数据后，需要对数据进行归一化，使各特征处于同一数量级，消除特征之间的量纲影响。</p><p class="text-idt25" data-id="90">特征选择</p><p class="text-idt25" data-id="91">本次研究的数据特征包含13个区域的注视频次特征（13个）、13个区域的注视时长特征（13个）、13个区域分别的转移概率特征（169个），共计195个特征。这195个特征中，有很大一部分特征和本次研究的相关性很低，例如从1前方道路到1前方道路的转移概率，其理论值和实际值应该均为0，对实验的研究并无帮助，这一类特征显然没有用处。同时，特征选择可以减少数据的维度，能有效提高训练模型的速度，因此需要进行特征选择。</p><p class="text-idt25" data-id="92">本研究中首先采用FEAST算法得到优选特征参考排序，然后进行显著性检验，对特征选择结果进行优化。</p><p class="text-idt25" data-id="93">FEAST算法简介</p><p class="text-idt25" data-id="94">对特征的筛选有相应的算法，本次研究选用的算法为FEAST（a FEAture Selection Toolbox for C and MATLAB）算法。FEAST提供了基于互信息的特征优选算法（Joint Mutual Information，JMI）的实现，它以离散化的数据为输入，返回所选出的特征的序号[16]。</p><p class="text-idt25" data-id="95">该算法综合考虑了候选特征之间的相关性、冗余度以及互补性，可更优的表达不同分类之间的特性差异，提高分类精度。</p><p class="text-idt25" data-id="96">显著性检验简介</p><p class="text-idt25" data-id="97">显著性检验（significance test）一种根据样本数据信息判断样本总体的真实情况与假设是否存在显著性差异的统计学方法，可用于判断特征的显著性。</p><p class="text-idt25" data-id="98"> FEAST算法在输出优选特征时会提高一个参考排序，但由于 FEAST算法存在缺陷，显著性差异小的特征在排序结果中可能会较靠前，会导致某些显著性差异大的特征排序靠后，从而错过这些更优的特征，因此采用显著性检验对特征选择结果进行优化。</p><p class="text-idt25" data-id="99">显著性检验时，首先假设某个特征与驾驶意图不相关，即假设该特征的显著性差异小。然后输出一个P值，该P值代表了上述假设发生的概率。在统计学中，当P值小于0.05时，可认为上述假设为不可能事件，即该假设不成立。由此可得，当P越值小，某个特征与驾驶意图越相关，显著性差异越大。</p><p class="text-idt25" data-id="100">特征选择流程</p><p class="text-idt25" data-id="101">图3-1为本研究中特征选择的流程，该算法过程与冒泡排序的思想比较类似。</p><p class="text-idt25" data-id="102">首先采用FEAST算法筛选得到20个优选特征。</p><p class="text-idt25" data-id="103">第二，根据FEAST算法结果提供的重要性排序将特征均分为两组，第一组为优选元素，第二组内元素为备选元素。</p><p class="text-idt25" data-id="104">第三，进行显著性检验，计算出每个特征的P值。</p><p class="text-idt25" data-id="105">第四，初始化优选组的序号i和备选组的序号j，为后面的循环做准备。</p><p class="text-idt25" data-id="106">第五，优选组第 i个特征与备选组第 j个特征的 P值进行比较，若优先组特征的 P值高于第二组元素 P值，则互换，并计算准确率，然后 j加一直至 j等于10，即遍历完所有备选组特征。</p><p class="text-idt25" data-id="107">第六，保留替换前后准确率最高的替换，i加一和初始化j。重复步骤五，直至i等于10，即遍历完所有优选组特征。最终得到十个优化后的优选特征。</p><p class="text-idt25" data-id="108">特征选择流程图</p><p class="text-idt25" data-id="109">特征选择结果</p><p class="text-idt25" data-id="110">经过特征选择，前十位优选特征如表3-2所示。</p><p class="text-idt25" data-id="111">前十位优选特征</p><p class="text-idt25" data-id="112">优选特征信号灯状态</p><p class="text-idt25" data-id="113">绿灯红灯</p><p class="text-idt25" data-id="114">1右前方道路的注视时长前方道路到左侧的转移概率</p><p class="text-idt25" data-id="115">2前方道路的注视频次信号灯的注视频次</p><p class="text-idt25" data-id="116">3右前方道路的注视频次其他区域的注视频次</p><p class="text-idt25" data-id="117">4前方道路到左侧道路区域的转移概率前方道路的注视频次</p><p class="text-idt25" data-id="118">5左视镜的注视频次右前方道路的注视频次</p><p class="text-idt25" data-id="119">6前方道路到右前方道路的转移概率左侧的注视频次</p><p class="text-idt25" data-id="120">7前方道路到左侧的转移概率前方道路到左视镜的转移概率</p><p class="text-idt25" data-id="121">8左侧道路区域的注视时长左侧道路区域的注视时长</p><p class="text-idt25" data-id="122">9前方道路到左视镜的转移概率右视镜的注视时长</p><p class="text-idt25" data-id="123">10左侧道路区域的注视频次前方道路到右前方道路的转移概率</p><p class="text-idt25" data-id="124">从上表可以看出，相比于绿灯，在红灯情况下，与右侧有关的特征排序下降，说明驾驶员对右侧的关注度减少，同时可发现，驾驶员对信号灯和其他区域区域的关注度提升，与现实情况较贴合。</p><p class="text-idt25" data-id="125">视觉搜索模式析取</p><p class="text-idt25" data-id="126">本章的主要内容为析取驾驶员视觉搜索模式的过程，采用层次算法得到聚类，并对所得聚类结果进行分析。</p><p class="text-idt25" data-id="127">聚类算法简介</p><p class="text-idt25" data-id="128">聚类算法选择</p><p class="text-idt25" data-id="129">聚类是一种按照一定标准将无标记数据划分成不同的子集，从而发掘数据内在结构和规律的方法。每个子集称为簇，即人们所说的类。在聚类过程中，会优先合并相似度大的样本，从而使同一个簇内的样本尽可能相似，不同簇之间差异尽可能大。聚类得到的结果仅为簇的结构，簇所包含的内在含义需要使用者自行把握和定义，在本研究中，所得到的类（簇）即为驾驶员的视觉搜索模式。</p><p class="text-idt25" data-id="130">聚类分析的算法有多种，常见算法有：K-means、层次聚类算法、FCM聚类算法等等。因为在本研究中，无法事先得知驾驶员视觉搜索模式的数量，因此适合采用不需要输入分类个数的层次聚类算法，在生成聚类树之后，根据相关参数，再划分簇的个数。</p><p class="text-idt25" data-id="131">层次聚类算法</p><p class="text-idt25" data-id="132">层次聚类（ Hierarchical Clustering）属于聚类算法中的一种[17]，通过计算不同样本点间的距离并将距离最近的两个聚类簇合并，从而创建一棵有层次的聚类树。在聚类树中，所有原始样本点是树的最低层，树的顶层是一个聚类的根节点。</p><p class="text-idt25" data-id="133">创建聚类树有自下而上凝聚和自上而下分裂两种方法。凝聚的层次聚类方法刚开始每个点都认为是一个簇，然后寻找最相近的簇不断地合并。分裂的层次聚类方法即把所有的对象首先都放到一个簇，不断向下划分，直到满足某种设定的条件停止分裂。</p><p class="text-idt25" data-id="134">本研究中采用的是自下而上凝聚的方法，分别得到绿灯和红灯情况下，左转、直行、右转三种驾驶意图下的聚类结果</p><p class="text-idt25" data-id="135">聚类参数寻优</p><p class="text-idt25" data-id="136">层次聚类算法步骤如图4-1所示。首先确定距离计算方法，计算数据间的距离。然后根据所设定的连接方式，将距离最近的样本或簇合并，合并后将成为一个新的簇，不断循环合并过程，直至全部数据合并在同一个簇内，聚类结束。</p><p class="text-idt25" data-id="137">层次聚类流程图</p><p class="text-idt25" data-id="138">距离计算方式有：欧式距离（ euclidean）、欧氏距离平方（ squaredeuclidean）、标准化欧式距离（ seuclidean）、曼哈顿距离（ cityblock）、闵可夫斯基距离（ minkowski）、切比雪夫距离（ chebychev）、马哈拉诺比斯距离（ mahalanobis）、余弦相似度（ cosine）、皮尔逊相关系数（ correlation）、斯皮尔曼距离（ spearman）、汉明距离（ hamming）、杰卡德距离（ jaccard）。</p><p class="text-idt25" data-id="139">连接方式有：平均值连接法（ average linkage）、质心法（ centroid linkage）、全连接法（ complete linkage）、中值连接法（ median linkage）、单连接法（ single linkage）、离差平方和法（ Ward’ s method）、加权平均连接法（ weighted linkage）。</p><p class="text-idt25" data-id="140">不同的距离计算方式和连接方式会对聚类结果产生不同的影响，因此，在聚类之前需要确定最佳的距离计算方式和连接方式。在本研究中，用下面两个依据来对聚类结果进行评估，从而选出最佳聚类参数。</p><p class="text-idt25" data-id="141">1、相关系数要尽可能大。</p><p class="text-idt25" data-id="142">2、每个簇中样本数量不少于总样本量的33%。</p><p class="text-idt25" data-id="143">相关（cophenet）系数可用于检测二叉聚类树中各元素间的距离和实际的距离之间有多大的相关性。该系数越接近1，表示聚类效果越好。而对类中样本数量的限制，为后续有监督学习做准备。聚类划分的个数不宜太多，因此设置最佳聚类个数最多为3个，故选取33%。根据上述两个规则，可编写程序自动搜索最优聚类参数，程序流程图如图4-2所示。</p><p class="text-idt25" data-id="144">聚类参数寻优流程图</p><p class="text-idt25" data-id="145">所得结果如表4-1、表4-2，分别为绿灯和红灯情况下最佳聚类参数。</p><p class="text-idt25" data-id="146">绿灯最佳聚类参数</p><p class="text-idt25" data-id="147">最佳聚类参数距离计算方法连接方法相关系数</p><p class="text-idt25" data-id="148">左转切比雪夫距离平均值连接法0.735</p><p class="text-idt25" data-id="149">直行皮尔逊相关系数平均值连接法0.758</p><p class="text-idt25" data-id="150">右转余弦相似度离差平方和法0.598</p><p class="text-idt25" data-id="151">红灯最佳聚类参数</p><p class="text-idt25" data-id="152">最佳聚类参数距离计算方法连接方法相关系数</p><p class="text-idt25" data-id="153">左转标准化欧式距离加权平均连接法0.773</p><p class="text-idt25" data-id="154">直行切比雪夫距离离差平方和法0.391</p><p class="text-idt25" data-id="155">右转欧式距离加权平均连接法0.748</p><p class="text-idt25" data-id="156">以下对上述涉及到的距离计算方法以及连接方法进行简要描述。</p><p class="text-idt25" data-id="157">切比雪夫距离是其各坐标数值差绝对值的最大值。</p><p class="text-idt25" data-id="158">皮尔逊相关系数为两个指标之间的协方差和标准差的商，用于度量两个变量之间的相关程度，其值介于-1与1之间。</p><p class="text-idt25" data-id="159">余弦相似度为两个指标的夹角余弦值，夹角越小，余弦值越接近于1，它们的方向更加吻合，则越相似。</p><p class="text-idt25" data-id="160">欧式距离指在m维空间中两个点之间的真实距离。</p><p class="text-idt25" data-id="161">标准化欧式距离是将欧几里得距离优化的距离计算方法，先将数据进行标准化后再进行欧式距离的计算[18]。</p><p class="text-idt25" data-id="162">平均值连接法倾向于距离的平均值差异小的两个类。该介于单连接法和全连接法之间，它考虑到了类的结构，产生的分类具有相对的鲁棒性。</p><p class="text-idt25" data-id="163">离差平方和法[19]，倾向于在每一次合并时，使簇内的离差平方和的增量最小。</p><p class="text-idt25" data-id="164">加权平均连接法相似于平均值连接法，但是在计算类间距的时候给距离加上了相当于类中成员个数倒数的权重。</p><p class="text-idt25" data-id="165">聚类结果</p><p class="text-idt25" data-id="166">绿灯聚类树形图</p><p class="text-idt25" data-id="167">根据上一节所得最佳聚类参数，可以通过层次聚类，得到不同信号灯状态下不同驾驶意图的聚类树。如图4-3绿灯情况下的树形图。</p><p class="text-idt25" data-id="168">绿灯时左转的聚类树形图</p><p class="text-idt25" data-id="169">如图4-4、图4-5为直行与左转时的树形图。</p><p class="text-idt25" data-id="170">绿灯时直行的聚类树形图</p><p class="text-idt25" data-id="171">绿灯时右转的聚类树形图</p><p class="text-idt25" data-id="172">在每一次聚类合并过程中，会计算每一个新聚类中的不一致（inconsistent）系数。若不一致系数有大幅度增加，说明上一次并类效果比较好，因此可以参考不一致系数的变化，确定最佳分类个数，所得的类即为驾驶员视觉搜索模式。</p><p class="text-idt25" data-id="173">由不一致系数得，绿灯情况下，左转驾驶意图的数据可划分了两类，模式1占总样本量35.7%，模式2占总样本量64.3%</p><p class="text-idt25" data-id="174">直行驾驶意图的数据可划分了两类，模式1占总样本量39.3%，模式2占总样本量60.7%</p><p class="text-idt25" data-id="175">右转驾驶意图的数据可划分了两类，模式1占总样本量37.1%，模式2占总样本量62.9%。</p><p class="text-idt25" data-id="176">红灯聚类树形图</p><p class="text-idt25" data-id="177">如图4-6、图4-7、图4-8所示，分别为红灯情况下，左转、直行、右转的树形图。由不一致系数得，左转驾驶意图的数据可划分了两类，模式1占总样本量38.5%，模式2占总样本量61.5%</p><p class="text-idt25" data-id="178">直行驾驶意图的数据可划分了两类，模式1占总样本量63%，模式2占总样本量37%</p><p class="text-idt25" data-id="179">右转驾驶意图的数据可划分了两类，模式1占总样本量68.7%，模式2占总样本量31.3%。</p><p class="text-idt25" data-id="180">红灯时左转聚类树形图</p><p class="text-idt25" data-id="181">红灯时直行聚类树形图</p><p class="text-idt25" data-id="182">红灯时右转聚类树形图</p><p class="text-idt25" data-id="183">调和曲线分析聚类结果</p><p class="text-idt25" data-id="184">由于人对数字和图形的感觉不相同，数字较为抽象，而图片更为直观，人脑从文字中得到信息的速度不如从图片中得到信息的速度快。因此，对于复杂的数据可以采用数据可视化便于人们对数据的理解。本研究中特征数量众多，虽然进行了特征选择筛选出10个最有效特征，但维数依然较高，故本小结将绘制一种可将高维数据可视化的图——调和曲线，将聚类结果更好地呈现。</p><p class="text-idt25" data-id="185">调和曲线简介</p><p class="text-idt25" data-id="186">常见的数据可视化中，当数据处于维数较低时，可直接在空间中绘制图形，观测数据分布，如图4-9所示，分别为二维和三维时数据可视化方法。当维度超过三维时，无法直接绘制图形，因此需要采取映射的方式，将高维空间映射到低维平面。</p><p class="text-idt25" data-id="187">（a）二维  （b）三维</p><p class="text-idt25" data-id="188">低维数据可视化方法</p><p class="text-idt25" data-id="189">调和曲线是一种可将高维数据中结构可视化的图[20]，每一次观测数据（高维的数据）对应一条调和曲线。在本研究中的数据是高维数据，因此通过线性变换映射到二维平面上的曲线上，调和曲线可以表示本研究中不同类的特点。</p><p class="text-idt25" data-id="190">按照公式4-1，将每个样本的特征值转化为傅里叶序列的系数来创建曲，曲线纵坐标的值代表了傅里叶级数的系数（ t∈[0，1]）。</p><p class="text-idt25" data-id="191"> f( t)= x_1/√2+ x_2 sin⁡〖( t)+”” x_3 cos⁡〖( t)+〗〗⋯+ x_9 cos⁡〖( t)+”” x_10 sin⁡( t)〗（4-1）</p><p class="text-idt25" data-id="192">式中：</p><p class="text-idt25" data-id="193">f——傅里叶级数的系数；</p><p class="text-idt25" data-id="194">t——时间；</p><p class="text-idt25" data-id="195">xi——第i个特征。</p><p class="text-idt25" data-id="196">将每一类曲线标成不同颜色可以可视化聚类数据，属于相同类别的样本的曲线通常更加接近并构成了更大的结构。通过分析每个类的特征分布，可以观测分类结果是否恰当。</p><p class="text-idt25" data-id="197">不同驾驶意图的调和曲线</p><p class="text-idt25" data-id="198">对于左转驾驶意图下的调和曲线，绿灯和红灯的调和曲线如图4-10所示。</p><p class="text-idt25" data-id="199">（a）绿灯   （b）红灯</p><p class="text-idt25" data-id="200">左转的调和曲线（虚线表示25%到75%的数据范围）</p><p class="text-idt25" data-id="201">对于直行驾驶意图下的调和曲线，绿灯和红灯的调和曲线如图4-11所示。</p><p class="text-idt25" data-id="202">（a）绿灯  （b）红灯</p><p class="text-idt25" data-id="203">直行的调和曲线（虚线表示25%到75%的数据范围）</p><p class="text-idt25" data-id="204">对于右转驾驶意图下的调和曲线，绿灯和红灯的调和曲线如图4-12所示。</p><p class="text-idt25" data-id="205">（a）绿灯  （b）红灯</p><p class="text-idt25" data-id="206">右转的调和曲线（虚线表示25%到75%的数据范围）</p><p class="text-idt25" data-id="207">由调和曲线可以展示不同类之间彼此更不相同，不同类的四分位线和曲线形状差异较大，故认为分类结果较为良好。</p><p class="text-idt25" data-id="208">模式特征分析</p><p class="text-idt25" data-id="209">本小节基于特征分析不同模式之间的差别，总结不同模式的在特征上表现的规律及特点，同时为其命名以便于对不同视觉搜索模式的理解。</p><p class="text-idt25" data-id="210">绿灯模式特征</p><p class="text-idt25" data-id="211">首先，讨论绿灯情况下三种驾驶意图的视觉搜索模式。为了方便作图，将特征分别编号，并按其方位划分为左向、前向、右向三类。</p><p class="text-idt25" data-id="212">与左向相关的特征：1左侧道路区域的注视时长、2左侧道路区域的注视频次、3左视镜的注视频次、4前方道路到左侧的转移概率、5前方道路到左视镜的转移概率、6前方道路到左侧道路区域的转移概率。</p><p class="text-idt25" data-id="213">与前向相关的特征：7前方道路的注视频次。</p><p class="text-idt25" data-id="214">与右向相关的特征：8前方道路到右前方道路的转移概率、9右前方道路的注视时长、10右前方道路的注视频次。</p><p class="text-idt25" data-id="215">从图4-13可分析得，绿灯情况下，左转驾驶意图下有两种视觉搜索模式。模式1（即为图中的曲线 L）对于左视镜、左侧道路等关注度较高，与右向有关的特征数值普遍较低，可认为该模式较倾向于关注左向，因此将其命名为模式 L。</p><p class="text-idt25" data-id="216">模式2（即为图中的曲线 LS）关于左向特征的转移概率较低，但在该方向上的注视频次和时长较模式是1有大幅度提高，因此也可认为模式2对于左向的关注度也较高。同时前方道路的注视频次数值非常突出，可认为驾驶员对前向道路也保持相当的关注度，因此将模式2命名为模式LS。</p><p class="text-idt25" data-id="217">绿灯左转时模式特征分布</p><p class="text-idt25" data-id="218">从图4-14可分析得，绿灯情况下，直行时有两种视觉搜索模式。模式1（即为图中的曲线 R）对于右前方道路的注视特征均比较突出，对前向道路关注中等，对左侧道路区域关注度非常低，可认为该模式下驾驶员将注意力大多集中在右向，因此将其命名为模式 R。</p><p class="text-idt25" data-id="219">模式2（即为图中的曲线 LS）不仅前方道路关注度较高，同时也关注左侧道路，因此可认为该模式较倾向于关注前向和左向，将其命名为模式 LS。</p><p class="text-idt25" data-id="220">绿灯直行时模式特征分布</p><p class="text-idt25" data-id="221">从图4-15可得，绿灯情况下，右转驾驶意图下有两种视觉搜索模式。模式1（即为图中的曲线 LS）对于左视镜和前方道路的关注度较高，可认为该模式较倾向于关注前向和左向，因此将其命名为模式 LS。</p><p class="text-idt25" data-id="222">相比于模式1，模式2（即为图中的曲线 R）对于右前方道路的关注度更高，可认为该模式较倾向于关注右向，因此将其命名为模式 R。</p><p class="text-idt25" data-id="223">绿灯右转时模式特征分布</p><p class="text-idt25" data-id="224">对比三种驾驶意图的视觉搜索模式之间的差别可分析得，每种驾驶意图下都存在侧重关注前方的模式，说明前方道路是驾驶员重点关注的区域。左转时，两种视觉搜索模式对左向的关注重点不同，模式L侧重关注左视镜即车辆后方，模式LS侧重关注左侧区域即车辆前方；直行时存在一种模式对左侧道路的关注度非常低；右转时两种视觉搜索模式对左侧道路的关注度均较低。</p><p class="text-idt25" data-id="225">红灯模式特征</p><p class="text-idt25" data-id="226">与绿灯时类似，将特征选择后的特征分别编号，并按其方位划分为左向、前向、右向三类。其中特征“其他区域的注视频次”与“信号灯的注视频次”按照图2-2位置，将其归为与前向相关。</p><p class="text-idt25" data-id="227">与左向相关的特征：1左侧的注视频次、2左侧道路区域的注视时长、3前方道路到左视镜的转移概率、4前方道路到左侧的转移概率</p><p class="text-idt25" data-id="228">与前向相关的特征：5前方道路的注视频次、6其他区域的注视频次、7信号灯的注视频次</p><p class="text-idt25" data-id="229">与右向相关的特征：8前方道路到右前方道路的转移概率、9右前方道路的注视频次、10右视镜的注视时长。</p><p class="text-idt25" data-id="230">由图4-16可得，红灯情况下，左转驾驶意图下有两种视觉搜索模式。模式1（即为图中的曲线 X）的特点为信号灯的注视频次和前方道路到左侧的转移概率较高，但由于前方道路的注视频次处于中等水平，再加上左侧的频次和时长较低，所以可认为驾驶员对左向关注度低，故分析得该模式对于信号灯关注较高，因此将其命名为模式 X。</p><p class="text-idt25" data-id="231">模式2（即为图中的曲线L）对于左侧道路的关注度非常突出，因此将其命名为模式L。</p><p class="text-idt25" data-id="232">红灯左转时模式特征分布</p><p class="text-idt25" data-id="233">由图4-17可分析得，红灯情况下，直行时有两种视觉搜索模式。模式1（即为图中的曲线X）与左转时的模式X非常类似，并且对于左侧和右侧的关注度更低，故同样可将其命名为模式X</p><p class="text-idt25" data-id="234">模式2（即为图中的曲线 XC）的信号灯注视频次较高，相比于模式1，其他特征的数值也相对较高，原因可能是模式1时，驾驶员对于信号灯的注视时间相对更长，因此更方面数值不如模式2高。而驾驶员处于模式2时，驾驶员更倾向于四处扫射，因此转移概率、注视频次等会更高，将其命名为模式XC。</p><p class="text-idt25" data-id="235">红灯直行时模式特征分布</p><p class="text-idt25" data-id="236">从图4-18可得，右转驾驶意图下有两种视觉搜索模式。</p><p class="text-idt25" data-id="237">红灯右转时模式特征分布</p><p class="text-idt25" data-id="238">模式1（即为图中的曲线 LSX）对于前方道路、信号灯和左侧的关注度较高，对右侧的关注度较低，因此将其命名为模式 LSX。模式2（即为图中的曲线RX）下对信号灯及右侧关注度较高。虽然关于前向到左向的转移概率较高，但驾驶员在对前向的关注度较低，因此将该模式命名为RX。</p><p class="text-idt25" data-id="239">对比三种驾驶意图的视觉搜索模式之间的差别可分析得，相对于绿灯而言，红灯时驾驶员对信号灯区域的关注度均较高。左转时，模式L占样本总量61.5%，说明驾驶员在等红灯时较倾向于关注左侧道路。直行时，驾驶员对左右两侧的关注度降低，对信号灯区域的关注度在三种驾驶意图中最高。右转时，虽然不受红灯限制，但数据表明，驾驶员依然会对信号灯保持一定的关注度。</p><p class="text-idt25" data-id="240">本章小结</p><p class="text-idt25" data-id="241">在本章中，首先采用层次聚类算法，析取得到驾驶员在不同驾驶意图下的视觉搜索模式并绘制调和曲线将聚类结果可视化。然后利用模式的特征绘制折线图进一步分析，总结不同模式的表现出的规律特点。主要结论如下：</p><p class="text-idt25" data-id="242">在绿灯情况下，左转时存在模式L、模式LS；直行时存在模式R、模式LS；右转时存在模式LS、模式R。每种驾驶意图下都存在侧重关注前方的模式，说明前方道路是驾驶员重点关注的区域。左转时，两种视觉搜索模式对左向的关注重点不同，一种侧重车辆左后方，一种侧重即车辆左前方。</p><p class="text-idt25" data-id="243">在红灯情况下，左转时存在模式X、模式L；直行时存在模式X、模式XC；右转时存在模式LSX、模式RX。信号灯区域是驾驶员的重点关注区域，其中直行时，驾驶员对信号灯区域的关注度在三种驾驶意图中最高。</p><p class="text-idt25" data-id="244">建模与预测</p><p class="text-idt25" data-id="245">本章的主要内容为基于前面研究得到的驾驶员的视觉搜索模式，提出一种将聚类结果与有监督学习结合的新预方法，其中采用的有监督学习算法为支持向量机（ LibSVM）和随机森林（ Random Forest），并配合网格搜索法和交叉验证，得到最佳模型参数。最后将新预测方法与传统有监督学习方法对比分析。</p><p class="text-idt25" data-id="246">具体的建模和预测过程均由MATLAB编程完成，相关程序见附录。</p><p class="text-idt25" data-id="247">有监督学习算法简介</p><p class="text-idt25" data-id="248">机器学习领域的算法成千上百，本次研究的分类问题所适应的算法也很多。针对这个问题，本次研究需要对算法进行优选。 S. B. Kotsiantis[21]详细分析了六种常见机器学习分类算法的优缺点，并对这些算法进行了分类准确率、分类速度、学习速度、过拟合风险处理能力等方面进行了对比。</p><p class="text-idt25" data-id="249">针对其中五种分类算法（随机森林、神经网络、朴素贝叶斯、k近邻、支持向量机）部分的对比分析结果，整理成表5-1。</p><p class="text-idt25" data-id="250">分类算法性能对比表</p><p class="text-idt25" data-id="251">机器学习分类算法随机森林</p><p class="text-idt25" data-id="252">（RF）神经网络</p><p class="text-idt25" data-id="253">（NN）朴素贝叶斯k近邻</p><p class="text-idt25" data-id="254">（kNN）支持向量机</p><p class="text-idt25" data-id="255">（SVM）</p><p class="text-idt25" data-id="256">分类准确率**************</p><p class="text-idt25" data-id="257">分类速度*****************</p><p class="text-idt25" data-id="258">学习速度*************</p><p class="text-idt25" data-id="259">过拟合风险处理能力*************</p><p class="text-idt25" data-id="260">鲁棒性**************</p><p class="text-idt25" data-id="261">从表中可以看出，在最主要的算法要求——分类准确率这一项上，随机森林和支持向量机具有很大的优势，其次为神经网络算法。对过拟合风险的处理能力，随机森林也占有很大优势，支持向量机略差。鲁棒性这一项上，随机森林和支持向量机也远远优于另外三种算法。分类速度和学习速度在本次研究中不是很重要的因素。</p><p class="text-idt25" data-id="262">综合上述性能特征，本次研究选取支持向量机和随机森林作为下一步建模预测的分类算法。</p><p class="text-idt25" data-id="263">支持向量机算法简介</p><p class="text-idt25" data-id="264">支持向量机（Support Vector Machine）是机器学习中一种分类快速性能可靠分类算法，可以在数据量有限的情况下很好地完成任务。该算法是利用最小化结构化风险来增强学习机泛化能力，使得经验风险和置信范围的达到最小，进而实现在数据样本量较小的条件下，同样可以得到比较优秀的统计规律的目的。支持向量机的分类策略是最大化两个类之间的间隔，因此在特征空间上可使间隔最大化的线性分类器为该算法的基本模型定义[22]。</p><p class="text-idt25" data-id="265">若有两组不同种类的数据分布在一个二维平面上，可以用一条线将其分成两部分，这条线便定义为超平面，其两边代表了不同的数据，有不同的数据标签。如图5-1所示。</p><p class="text-idt25" data-id="266">超平面区分两类数据</p><p class="text-idt25" data-id="267">一般而言，对一个数据点进行分类，这个点距离超平面的远近可以表示为分类预测的确信或者准确程度。那么如果这个“间隔”越大，分类的确信度也就越大。所以，为了使得分类确信度尽量高，需要让所选的超平面能够最大化这个“间隔”值。这个“间隔”值定义为图5-2中Gap的一半。虚线上点称为支持向量（Support Vector）。</p><p class="text-idt25" data-id="268">分类确信度表示</p><p class="text-idt25" data-id="269">以上是支持向量机在线性可分时的情形，当线性不可分时，通过核函数将低维数据映射到高维空间，从而将非线性问题转化为线性问题，然后在高维空间中寻找最优超平面。如图5-3所示，图中离超平面最近的球就是支持向量。</p><p class="text-idt25" data-id="270">通过核函数映射到高维空间</p><p class="text-idt25" data-id="271">LibSVM是一种完善版本的支持向量机，可用于完成本多分类问题。本次在MATLAB平台上采用LibSVM进行驾驶员意图预测[23]。</p><p class="text-idt25" data-id="272">随机森林算法简介</p><p class="text-idt25" data-id="273">随机森林（ Random Forest）是指利用多棵树对样本进行训练并预测的一种分类器，它同样可以用于用户回归，其输出的类别是由个别树输出的类别的种数而定的。简单来说，随机森林就是由多棵CART（Classification And Regression Tree）构成的[24]。对于每棵树，它们使用的训练集是从总的训练集中有放回采样出来的，这也就代表着总的训练集中的有些样本可能多次出现在一棵树中，也可能从未出现在一棵树的训练集中。如图5-4所示为随机森林图解。</p><p class="text-idt25" data-id="274">随机森林图解</p><p class="text-idt25" data-id="275">首先，从给定的训练集中通过多次随机的可重复的采样得到多个数据集。接着，对每个数据集构造一棵决策树，其构造过程为通过迭代将数据点分到下面左右两个子集中，该过程被称为分割过程。它实际上是将空间用超平面进行划分的一种方法，每次分割都将当前空间一分为二。然后，在每个叶节点处通过统计训练集中来分析此叶节点上的数据分布。这样的一个迭代训练过程会一直执行到用户所设定的最大树深度（nTree）或者直到不能通过继续分割来获取更多信息。</p><p class="text-idt25" data-id="276">聚类与有监督学习结合方法</p><p class="text-idt25" data-id="277">如图5-5所示，分别为聚类情况下，绘制的左转、直行、右转三种驾驶意图的调和曲线。绿灯情况下，直行和右转的调和曲线结构比较类似，因此分类器不容易区分这两类数据。红灯情况下，左转和右转的调和曲结构也类似，对于分类器来说，区分这两类数据也存在一定难度，因此若能使不同驾驶意图的数据结构区分比较大，可以提高预测准确率。</p><p class="text-idt25" data-id="278">（a）绿灯  （b）红灯</p><p class="text-idt25" data-id="279">未分别聚类时的调和曲线</p><p class="text-idt25" data-id="280">本论文第4章中得到了不同驾驶意图下的驾驶员动态视觉搜索模式，并且经绘制调和曲线将数据可视化后，发现大部分驾驶意图下的视觉搜索模式之间数据结构相差较大，因此提出一种将聚类结果与有监督学习结合的新预测方法，将析取所得的模式作为新标签从而提高分类器的准确率，流程图见图5-6。</p><p class="text-idt25" data-id="281">首先将得到的六种视觉搜索模式（即聚类后得到的类）作为新标签，进行有监督学习模型训练，当输入一个新样本进行预测时，输出六种视觉搜索模式的发生概率。</p><p class="text-idt25" data-id="282">视觉搜索模式可按其归属分为左转、直行、右转三种，将归属相同的模式概率相加，得到不同驾驶意图的发生概率。最后，输出概率最高的意图作为预测结果。</p><p class="text-idt25" data-id="283">本论文中，新方法指代的是上述将聚类结果与有监督学习结合的方法，传统方法指代的是不经过聚类直接进行有监督学习的方法。</p><p class="text-idt25" data-id="284">聚类与有监督学习结合流程图</p><p class="text-idt25" data-id="285">支持向量机预测</p><p class="text-idt25" data-id="286">网格搜索法参数寻优</p><p class="text-idt25" data-id="287">支持向量机算法有两个重要参数分别为c和g，在建立模型时需要对这两个参数进行寻优[25]。</p><p class="text-idt25" data-id="288">参数c是惩罚系数，即对误差的宽容度。c越高，说明越不能容忍出现误差，容易发生过拟合，即对训练集准确高但对测试集准确率低。c越小，容易欠拟合，对测试集的准确率变低。c过大或过小，泛化能力均降低。</p><p class="text-idt25" data-id="289">参数g也称为gamma系数，是选择RBF函数作为核函数后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布。g过大，容易过拟合，g过小，容易欠拟合。</p><p class="text-idt25" data-id="290">网格搜索法是指定参数值的一种穷举搜索方法，通过尝试各种可能的c、g值，然后进行交叉验证，找出使交叉验证精确度最高的c和g。 该方法有以下优点：</p><p class="text-idt25" data-id="291">全面搜索参数，可找到全局最优解；</p><p class="text-idt25" data-id="292">实现简单，用多重循环结构即可实现；</p><p class="text-idt25" data-id="293">若参数比较少，与高级算法相比，时间复杂度不会高太多；</p><p class="text-idt25" data-id="294">可并行性高，因为c、g组合对是相互独立的。</p><p class="text-idt25" data-id="295">通过网格搜索法，可得到不同 c， g下的准确率，为了方便将结果可视化展示，绘制等高线图，横轴表示参数 c，纵轴表示参数 g，等高线上的数值表示准确率。</p><p class="text-idt25" data-id="296">交叉验证简介</p><p class="text-idt25" data-id="297">交叉验证（ Cross- validation）是一种将数据集均分成 n个子集，并将这 n份数据轮流充当测试集和训练集的方法，可以提高数据利用率[26]。常见划分份数为十，也称为十折交叉验证，即均分为十份后，一份作为测试集，其余九份作为训练集，如图5-7为十折交叉验证的过程。</p><p class="text-idt25" data-id="298">十折交叉验证图解</p><p class="text-idt25" data-id="299"> Ei为每轮测试准确率，可得到十轮测试准确率，再取平均值，为了增加实验结果准确性还可以进行多次交叉验证后再求总实验次数的平均值。</p><p class="text-idt25" data-id="300">本研究中采用十折交叉验证和五折交叉验证，并实验十次取平均值。先设置 c和 g的搜索范围为0至10，每次步长为0.5，再根据实际等高线图缩小搜索范围，每次步长为0.05，找到最佳参数。</p><p class="text-idt25" data-id="301">新方法预测结果</p><p class="text-idt25" data-id="302">如图5-8所示，分别为绿灯情况下，十折交叉验证和五折交叉验证时，新方法的准确率。</p><p class="text-idt25" data-id="303">十折交叉验证时，图中显示准确率最高为67%，此时对应的参数g范围是1至2，惩罚系数c范围是6至9。在此范围内继续缩小，最终可得当g=1.4，c=7.55时，准确率最高为67.6%。</p><p class="text-idt25" data-id="304">五折交叉验证时，图中显示准确率最高为66%，此时对应的参数 g范围是0.5至2，惩罚系数 c从7至10，因为当 c=10时，仍呈现准确率上升趋势，故在进一步搜索时，惩罚系数 c范围可设置为7至13。最终可得当g=0.75，c=12.8时，准确率为66.4%。</p><p class="text-idt25" data-id="305">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="306">绿灯时新方法的准确率</p><p class="text-idt25" data-id="307">如图5-9所示，分别为红灯情况下，十折交叉验证和五折交叉验证时，新方法的准确率。</p><p class="text-idt25" data-id="308">十折交叉验证时，图中显示准确率最高为70%，此时对应的参数 g范围是0.5至1.5，惩罚系数 c从5至10，因为当 c=10时，仍呈现准确率上升趋势，故惩罚系数 c搜索范围设置为4.8至15.2。最终可得当g=0.9，c=10.3时，准确率为71.9%。</p><p class="text-idt25" data-id="309">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="310">红灯时新方法的准确率</p><p class="text-idt25" data-id="311">五折交叉验证时，图中显示准确率最高为66%，此时对应的参数 g范围是0.5至1.5，惩罚系数 c范围是7.5至9.5。在此范围内继续缩小，最终可得当g=1.05，c=8.55时，准确率为66.7%。</p><p class="text-idt25" data-id="312">传统方法预测结果</p><p class="text-idt25" data-id="313">如图5-10所示，分别为绿灯情况下，十折交叉验证和五折交叉验证时，采用传统支持向量机算法的准确率。</p><p class="text-idt25" data-id="314">十折交叉验证时，图中显示准确率最高为66%，此时对应的参数 g范围是1.5至2，惩罚系数 c范围是5.5至8.5。在此范围内继续缩小，最终可得当g=1.85，c=7.05时，准确率为66.5%。</p><p class="text-idt25" data-id="315">五折交叉验证时，图中显示准确率最高为65%，此时对应的参数 g范围是1.5至2.5，惩罚系数 c从5.5至10，因为当 c=10时，仍呈现准确率上升趋势，故惩罚系数 c搜索范围设置为5.5至14.5。最终可得当g=1.55，c=13.8时，准确率为65.8%。</p><p class="text-idt25" data-id="316">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="317">绿灯时传统方法的准确率</p><p class="text-idt25" data-id="318">如图5-11所示，分别为红灯情况下，十折交叉验证和五折交叉验证时，新方法的准确率。</p><p class="text-idt25" data-id="319">十折交叉验证时，图中显示准确率最高为62%，此时对应的参数 g范围是0.5至1.5，惩罚系数 c从5至10，因为当 c=10时，仍呈现准确率上升趋势，故惩罚系数 c搜索范围设置为5至15。最终可得当g=1.35，c=9.85时，准确率为62.9%。</p><p class="text-idt25" data-id="320">五折交叉验证时，图中显示准确率最高为61%，此时对应的参数 g范围是1至2，惩罚系数 c范围是5至8.5和9至10，因为当 c=10时，仍呈现准确率上升趋势，故惩罚系数 c搜索范围设置为两段，分别为5至8.5和9至11。在此范围内继续缩小，最终可得当g=1.45，c=7时，准确率为61.6%</p><p class="text-idt25" data-id="321">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="322">红灯时传统方法的准确率</p><p class="text-idt25" data-id="323">新旧方法效能比对</p><p class="text-idt25" data-id="324">为了对比新方法与传统方法的优劣，将新方法的准确率减去传统方法的准确率，得到相同参数下，两种方法的准确率差值。</p><p class="text-idt25" data-id="325">绿灯情况下如图5-12所示，图（a）为十折交叉验证时两种方法的差值。新方法的准确普遍高于传统方法。</p><p class="text-idt25" data-id="326">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="327">绿灯时新方法与传统方法的准确率差值</p><p class="text-idt25" data-id="328">在惩罚系数 c和参数 g较低时，新方法对准确率的提升最为明显，比传统方法的准确率最多高出6.3%，但随着 c和 g的增加，这种优势在逐渐减少。图（b）为五折交叉验证时的结果，表现出的规律与十折交叉验证情况时类似，其中新方法准确率最多高出5.2%。</p><p class="text-idt25" data-id="329">红灯情况下如图5-13所示，新方法与传统方法的准确率差值。红灯呈现出与绿灯类似的规律，随着参数的增大，新方法的优势逐渐减少。但是与绿灯不同的是，红灯下新方法对准确率的提升更为明显，十折交叉验证时最多可提高9%，五折交叉验证时，最多可提高7.8%。</p><p class="text-idt25" data-id="330">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="331">红灯时新方法与传统方法的准确率差值</p><p class="text-idt25" data-id="332">随机森林预测</p><p class="text-idt25" data-id="333">基于随机森林算法建模需要的基本参数有两个，一为训练集，二为决策树数量。训练集即为第三章中预处理后得到的数据。随机森林的参数为决策树数量，若决策树数量过小，则准确率不高。随着决策树数量的增加，准确率的增长率呈现先增大后减少的趋势，决策树数量过多不仅而且模型训练速度会变慢，效益变低，为了确定所采用的的随机森林分类器中决策树的数量，本研究绘制了关于决策树数量对驾驶意图预测的准确率影响的折线图。由折线图观察准确率的变化趋势，选取准确率较高且决策树数量较少的点作为最佳参数。</p><p class="text-idt25" data-id="334">本研究中，决策树数量变化范围为5至200，每次步长为5。为了防止过拟合，同样采用十折交叉验证和五折交叉验证的方法。</p><p class="text-idt25" data-id="335">绿灯</p><p class="text-idt25" data-id="336">图5-14表示绿灯情况下，新方法与传统方法在使用随机森林时，准确率随着树数量发生的变化，无论哪种方法，曲折到后面趋于平稳，选择趋于平稳时的临界点作为最佳参数。</p><p class="text-idt25" data-id="337">十折交叉验证时，新方法的最佳决策树数量为115棵，此时准确率为70.6%，传统方法的最佳决策树数量为105棵，此时准确率为68.8%。五折交叉验证时，新方法最佳决策树数量为65棵，此时准确率为69.5%，传统方法的最佳决策树数量为55棵，此时最佳准确率为67.4%</p><p class="text-idt25" data-id="338">对比新旧方法，十折交叉验证时，当决策树数量小于25时，新方法与传统方法准确率相近，当决策树数量超过25后，新方法的优势较明显，准确率比传统方法高。五折交叉验证时，绝大部分情况下，新方法准确率比传统方法高。上述情况说明，新方法能够起到提高一定准确率的作用。</p><p class="text-idt25" data-id="339">对比不同的交叉验证，当采用新方法时，十折交叉验证的准确率比五折交叉验证时高，而采用传统方法时，依然十折交叉验证的准确率较高。因此在绿灯情况下，采用新方法和十折交叉验证可获得较好的分类准确率，此时最佳决策树的数量为90棵，准确率为71.6%。</p><p class="text-idt25" data-id="340">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="341">绿灯下随机森林的新旧方法准确率对比</p><p class="text-idt25" data-id="342">红灯</p><p class="text-idt25" data-id="343">图5-15表示红灯情况下，新方法与传统方法在使用随机森林时，准确率随着树数量发生的变化。</p><p class="text-idt25" data-id="344">十折交叉验证时，新方法的最佳决策树数量为90棵，此时准确率为70.9%，传统方法的最佳决策树数量为100棵，此时准确率为68.9%。五折交叉验证时，新方法最佳决策树数量为85棵，此时准确率为69.7%，传统方法的最佳决策树数量为70棵，此时最佳准确率为67.7%</p><p class="text-idt25" data-id="345">对比新旧方法，十折交叉验证时，新方法准确率始终比传统方法高，五折交叉验证时也表现出同样的规律。</p><p class="text-idt25" data-id="346">对比不同的交叉验证，结果与绿灯情况下类似，无论是哪种方法，十折交叉验证的准确率均比五折交叉验证的高，说明红灯情况下，采用新方法和十折交叉验证可获得较好的分类准确率，此时最佳决策树的数量为80棵，准确率为70.8%。</p><p class="text-idt25" data-id="347">（a）十折交叉验证   （b）五折交叉验证</p><p class="text-idt25" data-id="348">红灯下随机森林的新旧方法准确率对比</p><p class="text-idt25" data-id="349">对比不同的信号灯状态，对于新方法而言，十折交叉验证时，绿灯的准确率趋于平稳时与红灯相近，均在70.7%附近浮动，五折交叉验证时绿灯与红灯的准确率也相差不大，均在69.6%附近浮动。说明即时信号灯状态不同，新方法的预测准确率依然相近。</p><p class="text-idt25" data-id="350">本章小结</p><p class="text-idt25" data-id="351">本章提出了一种将聚类结果与有监督学习相结合的新预测方法，采用的有监督学习算法有支持向量和随机森林。为了提高数据利用率采用了交叉验证，同时还采用了网格搜索法进行参数的寻优。最后进行了新方法与传统方法准确率的对比。</p><p class="text-idt25" data-id="352">结果表明，新方法可在一定程度上提高预测准确率，如表5-2所示，为新方法准确率与传统方法准确率的最大差值。</p><p class="text-idt25" data-id="353">不同算法下新旧方法准确率的最大差值</p><p class="text-idt25" data-id="354">信号灯状态支持向量机随机森林</p><p class="text-idt25" data-id="355">十折交叉验证五折交叉验证十折交叉验证五折交叉验证</p><p class="text-idt25" data-id="356">绿灯6.3%5.2%1.8%2%</p><p class="text-idt25" data-id="357">红灯9%7.8%2%2%</p><p class="text-idt25" data-id="358">在相同参数的情况下，对于支持向量机，在参数c和g较低时，新方法比传统方法的优势更为明显，最高可提高准确率9%。十折交叉验证的提升程度比五折验证时高，红灯状态下对准确率的提升比绿灯时高。</p><p class="text-idt25" data-id="359">对于随机森林，新方法对准确率提升程度较少。十折与五折交叉验证之间、红绿灯之间，对准确率的的提升程度差异不大。</p><p class="text-idt25" data-id="360"> </p><p class="text-idt25" data-id="361">结论</p><p class="text-idt25" data-id="362">本研究在现有的数据基础上，完成了驾驶员动态视觉搜索模式的析取与分析，并且基于所得模式提出一种将聚类结果与有监督学习算法相结合的新预测方法。研究将驾驶员的视觉区域划分为13个区，并将注视频次、注视时长、转移概率作为衡量驾驶员注视特性的指标。在特征选择中，在FEAST算法的基础上，配合显著性检验筛选出了一些系列具有代表性的特征作为驾驶意图预测建模的主要特征。</p><p class="text-idt25" data-id="363">在视觉搜索模式析取时，采用层次聚类算法，绘制了聚类树形图和调和曲线观测聚类结果，通过模式的特征分析了不同模式的规律，并根据其特点为其命名。</p><p class="text-idt25" data-id="364">在建模预测时，本研究将所得的视觉搜索模式与有监督学习方法相结合，提出一种新的预测方法，并成功实现了其对分类准确率的优化。其中采用的有监督学习方法分别为：支持向量机和随机森林。为了提高数据利用率采用了交叉验证，同时还采用了网格搜索法进行参数的寻优。最后进行了新方法与传统方法准确率的对比。</p><p class="text-idt25" data-id="365">本章在总结了前述众多分析和结果以后，得出以下主要结论：</p><p class="text-idt25" data-id="366">1、在绿灯情况下，左转时存在模式L、模式LS；直行时存在模式R、模式LS；右转时存在模式LS、模式R。每种驾驶意图下都存在侧重关注前方的模式，说明前方道路是驾驶员重点关注的区域。左转时，两种视觉搜索模式对左向的关注重点不同，模式L侧重关注左视镜即车辆后方，模式LS侧重关注左侧区域即车辆前方；直行时存在一种模式对左侧道路的关注度非常低；右转时两种视觉搜索模式对左侧道路的关注度均较低。</p><p class="text-idt25" data-id="367">2、在红灯情况下，左转时存在模式X、模式L；直行时存在模式X、模式XC；右转时存在模式 LSX、模式 RX对比三种驾驶意图的视觉搜索模式之间的差别可分析得，相对于绿灯而言，红灯时驾驶员对信号灯区域的关注度均较高。左转时，模式L占样本总量61.5%，说明驾驶员在等红灯时较倾向于关注左侧道路。直行时，驾驶员对左右两侧的关注度降低，对信号灯区域的关注度在三种驾驶意图中最高。右转时，虽然不受红灯限制，但数据表明，驾驶员依然会对信号灯保持一定的关注度。</p><p class="text-idt25" data-id="368">3、采用SVM算法时，绿灯情况下，十折交叉验证时新方法的准确普遍高于传统方法。在惩罚系数 c和参数 g较低时，新方法对准确率的提升最为明显，比传统方法的准确率最多高出6.3%，但随着 c和 g的增加，这种优势在逐渐减少。五折交叉验证时，表现出的规律与十折交叉验证情况时类似，其中新方法准确率最多高出5.2%。红情况下表现出的规律与绿灯类似，随着参数的增大，新方法的优势逐渐减少。但是与绿灯不同的是，红灯下新方法对准确率的提升更为明显，十折交叉验证时最多可提高9%，五折交叉验证时，最多可提高7.8%。</p><p class="text-idt25" data-id="369">4、采用随机森林算法时，新方法对于准确率的提高不如支持向量机明显，但依然能在一定程度上起到优化作用。在绿灯情况下，十折交叉验证时，新方法比传统方法准确率高1.8%，五折交叉验证时高2%。在红灯情况下，十折交叉验证时，新方法比传统方法准确率高2%，五折交叉验证时高2%。</p>        <div class="paper-footer">
            <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
            <p>Copyright © 2007-2018 PaperPass</p>
        </div>
    </div>

</div>
</body>
<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/Lib.js"></script>
<script type="text/javascript">
    Report.report_id = '5ae1409a68d42m3qy';
</script>
<script type="text/javascript">
    (function(System,$){
        var cache = new System.Cache(System.report_id,localStorage);
        $(function(){
            $.each(cache.get(),function(){
                $('[data-id='+this.id+']').addClass('g-font-color green').html(this.text);
            });

        });
    })(Report,jQuery);

</script>
</html>
